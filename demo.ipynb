{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D Scene Coordinate Prediction and Pose Estimation Demo\n",
    "\n",
    "This demo showcases how to use a pre-trained neural network to predict scene coordinates and estimate camera pose using the DSAC\\* algorithm. We will load point cloud data, process an image, perform inference, and visualize the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.cuda.amp import autocast\n",
    "from vis_3d import init_figure, plot_points, plot_camera\n",
    "from ace_network import Regressor\n",
    "from dataset import CamLocDataset\n",
    "import numpy as np\n",
    "import dsacstar\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Point Cloud Data\n",
    "\n",
    "First, we load the previously generated point cloud data and perform coordinate system transformations to prepare for further processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load point cloud data\n",
    "point_cloud_3d = np.loadtxt(\"results_folder/point_cloud_out.txt\")\n",
    "pc_xyz = point_cloud_3d[..., :3]\n",
    "\n",
    "# Convert from OpenGL coordinate system to OpenCV coordinate system\n",
    "pc_xyz[:, 1] = -pc_xyz[:, 1]\n",
    "pc_xyz[:, 2] = -pc_xyz[:, 2]\n",
    "\n",
    "# Color information\n",
    "color_N3 = point_cloud_3d[..., 3:] * 0.7\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Preprocess Image\n",
    "\n",
    "We load the test image from the dataset and perform necessary preprocessing, such as resizing and setting intrinsic parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image path\n",
    "queue_image_path = \"datasets/7scenes_redkitchen/test/rgb/seq-06-frame-000936.color.png\"\n",
    "\n",
    "# Create test dataset\n",
    "test_dataset = CamLocDataset(queue_image_path, image_short_size=480)\n",
    "test_dataset.set_external_focal_length(525)\n",
    "\n",
    "# Retrieve data\n",
    "image_1HW, _, _, _, intrinsics_33, _, _, filename, indice = test_dataset[0]\n",
    "\n",
    "# Open original image\n",
    "image_rgb = Image.open(queue_image_path)\n",
    "\n",
    "# Get original size\n",
    "original_size = image_rgb.size\n",
    "width, height = original_size\n",
    "\n",
    "# Resize image\n",
    "new_size = (width // 8, height // 8)\n",
    "resized_image_rgb = np.asarray(image_rgb.resize(new_size))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Pre-trained Network Models\n",
    "\n",
    "We load the pre-trained weights for the encoder and head networks, and set up the model for evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network weight paths\n",
    "encoder_path = \"xfeat.pt\"\n",
    "head_network_path = \"results_folder/ace_network.pt\"\n",
    "\n",
    "# Load network weights\n",
    "encoder_state_dict = torch.load(encoder_path, map_location=\"cpu\")\n",
    "head_state_dict = torch.load(head_network_path, map_location=\"cpu\")\n",
    "\n",
    "# Create regressor\n",
    "network = Regressor.create_from_split_state_dict(encoder_state_dict, head_state_dict)\n",
    "\n",
    "# Move to GPU and set to evaluation mode\n",
    "network = network.to('cuda')\n",
    "network.eval()\n",
    "\n",
    "# Disable gradient computation and move image to GPU\n",
    "with torch.no_grad():\n",
    "    image_1HW = image_1HW.to('cuda', non_blocking=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Scene Coordinates\n",
    "\n",
    "Using the neural network, we perform inference on the input image to predict 3D scene coordinates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    # Perform inference with automatic mixed precision\n",
    "    with autocast(enabled=True):\n",
    "        scene_coordinates_3HW = network(image_1HW.unsqueeze(0))[0]\n",
    "    \n",
    "    # Move to CPU and convert to float\n",
    "    scene_coordinates_3HW = scene_coordinates_3HW.float().cpu()\n",
    "    \n",
    "    # Extract intrinsic parameters\n",
    "    focal_length = intrinsics_33[0, 0].item()\n",
    "    ppX = intrinsics_33[0, 2].item()\n",
    "    ppY = intrinsics_33[1, 2].item()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate Pose Using DSAC\\*\n",
    "\n",
    "We use the DSAC\\* algorithm to compute the camera pose based on the predicted scene coordinates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize output pose matrix\n",
    "out_pose = torch.zeros((4, 4))\n",
    "\n",
    "# Estimate pose using DSAC*\n",
    "inlier_count = dsacstar.forward_rgb(\n",
    "    scene_coordinates_3HW.unsqueeze(0),\n",
    "    out_pose,\n",
    "    64,                    # Maximum iterations\n",
    "    10,                    # Inlier threshold\n",
    "    focal_length,\n",
    "    ppX,\n",
    "    ppY,\n",
    "    100,                   # RANSAC threshold\n",
    "    100,                   # RANSAC max iterations\n",
    "    network.OUTPUT_SUBSAMPLE,\n",
    "    1305                   # Random seed\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Prediction Results\n",
    "\n",
    "We use Matplotlib to display the original image and the normalized scene coordinates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Convert scene coordinates to NumPy array\n",
    "image_np = scene_coordinates_3HW.permute(1, 2, 0).numpy()\n",
    "\n",
    "# Normalize the scene coordinates for visualization\n",
    "lower = np.percentile(image_np, 25)\n",
    "upper = np.percentile(image_np, 75)\n",
    "sc = (image_np - lower) / (upper - lower)\n",
    "\n",
    "# Display original image\n",
    "axes[0].imshow(image_rgb)\n",
    "axes[0].set_title(\"Original Image\")\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Display normalized scene coordinates\n",
    "axes[1].imshow(sc)\n",
    "axes[1].set_title(\"Scene Coordinates\")\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D Visualization\n",
    "\n",
    "Using the `vis_3d` library, we visualize the scene coordinates, camera pose, and point cloud data in a 3D plot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize 3D figure\n",
    "fig = init_figure()\n",
    "\n",
    "# Plot predicted scene coordinates with corresponding colors\n",
    "plot_points(fig, scene_coordinates_3HW.view(3, -1).permute(1, 0).numpy(), resized_image_rgb.reshape((-1, 3)))\n",
    "\n",
    "# Plot camera pose\n",
    "plot_camera(\n",
    "    fig, \n",
    "    R=out_pose[:3, :3].numpy(), \n",
    "    t=out_pose[:3, 3].numpy(), \n",
    "    K=intrinsics_33.numpy(), \n",
    "    color='rgb(255, 255, 255)', \n",
    "    size=3, \n",
    "    fill=True, \n",
    "    text='queue_image'\n",
    ")\n",
    "\n",
    "# Plot original point cloud\n",
    "plot_points(fig, pc_xyz, color_N3)\n",
    "\n",
    "# Display the figure\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ace0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
